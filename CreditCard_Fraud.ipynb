{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOWmdTPULvrJ08cJW6lyIgc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emanuelcatao/CreditCardFraud/blob/main/CreditCard_Fraud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Etapas da Resolu√ß√£o do Problema:\n",
        "\n",
        "1 - **\"An√°lise explorat√≥ria dos dados (EDA)\":** Vamos primeiro buscar entender o dataset antes de aplicar os algoritmos. O objetivo primeiro desta etapa √© tentar visualizar a distribui√ß√£o das transa√ß√µes leg√≠timas e fraudulentas, bem como qualquer padr√£o ou tend√™ncia incomum que possa ser observada nessa an√°lise.\n",
        "\n",
        "2- **Pr√©-processamento de dados:** Depois de termos feito um reconhecimento do terreno em que estamos trabalhando, vamos lidar com quaisquer dados ausentes (se houverem) e dividir o dataset em conjuntos de treinamento e teste.\n",
        "\n",
        "3 - **Treinamento e avalia√ß√£o dos modelos:** Aqui √© talvez o que nos interesse mais.\n",
        "- Primeiro, treinar cada um dos tr√™s modelos especificados (Naive Bayes, √Årvore de Decis√£o e KNN) com o conjunto de treinamento.\n",
        "- Em seguida, avaliar cada modelo usando o conjunto de teste e calcular a precis√£o, para cada modelo.\n",
        "- Por fim, visualizar as fronteiras de decis√£o para as features escolhidas. Para isso, precisaremos escolher duas features para visualiza√ß√£o, uma vez que fronteiras de decis√£o s√£o mais facilmente visualizadas em duas dimens√µes - isso aqui depende tamb√©m.\n",
        "\n",
        "4 - **Conclus√£o**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "mjJZubuO26NM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMjCX9zt24oJ",
        "outputId": "1dffa541-3577-4069-83a4-354174e53b2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S√≥ a cabecinha üòè\n",
            "\n",
            "    distance_from_home  distance_from_last_transaction  \\\n",
            "0           57.877857                        0.311140   \n",
            "1           10.829943                        0.175592   \n",
            "2            5.091079                        0.805153   \n",
            "3            2.247564                        5.600044   \n",
            "4           44.190936                        0.566486   \n",
            "\n",
            "   ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
            "0                        1.945940              1.0        1.0   \n",
            "1                        1.294219              1.0        0.0   \n",
            "2                        0.427715              1.0        0.0   \n",
            "3                        0.362663              1.0        1.0   \n",
            "4                        2.222767              1.0        1.0   \n",
            "\n",
            "   used_pin_number  online_order  fraud  \n",
            "0              0.0           0.0    0.0  \n",
            "1              0.0           0.0    0.0  \n",
            "2              0.0           1.0    0.0  \n",
            "3              0.0           1.0    0.0  \n",
            "4              0.0           1.0    0.0  \n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000000 entries, 0 to 999999\n",
            "Data columns (total 8 columns):\n",
            " #   Column                          Non-Null Count    Dtype  \n",
            "---  ------                          --------------    -----  \n",
            " 0   distance_from_home              1000000 non-null  float64\n",
            " 1   distance_from_last_transaction  1000000 non-null  float64\n",
            " 2   ratio_to_median_purchase_price  1000000 non-null  float64\n",
            " 3   repeat_retailer                 1000000 non-null  float64\n",
            " 4   used_chip                       1000000 non-null  float64\n",
            " 5   used_pin_number                 1000000 non-null  float64\n",
            " 6   online_order                    1000000 non-null  float64\n",
            " 7   fraud                           1000000 non-null  float64\n",
            "dtypes: float64(8)\n",
            "memory usage: 61.0 MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Carregando o dataset\n",
        "data = pd.read_csv('/mnt/data/card_transdata.csv')\n",
        "\n",
        "print('S√≥ a cabecinha üòè\\n\\n', data.head(), end='\\n\\n')\n",
        "\n",
        "'''\n",
        "  mostra um resumo do dataframe: qtd_linhas,nomes_colunas,\n",
        "  qtd_nulos_coluna, tipo_dado_coluna, memoria usada\n",
        "'''\n",
        "print(data.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui o dataset foi carregado e temos uma vis√£o geral dos dados:\n",
        "- S√£o ao todo 1.000.000 entradas, divididas em 8 colunas (sendo uma delas a \"coluna alvo\", que cont√©m o indicativo de fraude)\n",
        "- N√£o h√° valores ausentes nas colunas (o que indica que j√° n√£o precisamos da parte do tratamento de dados ausentes. Isso aqui s√≥ aconteceu por que o conjunto de dados √© muito bem definido e se trata um problema para estudo).\n",
        "- Aparentemente cinco dessas colunas, a saber *repeat_retailer*, *used_chip*, *used_pin_number*, *online_order*, e *fraud*, parecem ter dados bin√°rios.\n",
        "\n",
        "\n",
        "Partimos para observar rapidamente a distribui√ß√£o de transa√ß√µes legitimas vs fraudulentas.\n"
      ],
      "metadata": {
        "id": "gYD9UDFF-IYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "    Aqui √© basicamente dito, na coluna 'fraud' da tabela, contabilize e o valor √© normalizado.\n",
        "    Basicamente conta todos os valores e atribui a quantidade √† chave correspondente. Como √© dito para normalizar,\n",
        "    ap√≥s contar todos, pega cada um deles e divide proporcionalmente √† quantidade total na coluna.\n",
        "    Isso aqui cria uma serie com o nome da coluna, os valores computados na serie s√£o do tipo float e\n",
        "    o retorno vai ser a s√©rie com a distribui√ß√£o proporcional dos valores na serie.\n",
        "'''\n",
        "fraud_distribution = data['fraud'].value_counts(normalize=True)\n",
        "\n",
        "print(fraud_distribution) # no colab nao precisa do print, mas fica ae"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMxTFi728jZU",
        "outputId": "87c0c5bd-8e88-4bf7-c541-77e3a543b15d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0    0.912597\n",
            "1.0    0.087403\n",
            "Name: fraud, dtype: float64\n"
          ]
        }
      ]
    }
  ]
}